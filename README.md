# ProiectLA
An in-depth and comprehensive analysis on Catalonia cell coverage dataset

"""LAPr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YQJQDjLcKagZiGJz--9YMFevOg8ZzfIa
"""

!pip install google-cloud-bigquery pyspark matplotlib scikit-learn

from google.cloud import bigquery
from pyspark.sql import SparkSession
from pyspark.sql.types import *
from pyspark.sql.functions import col, corr
import matplotlib.pyplot as plt
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import LinearRegression
from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression, RandomForestClassifier
from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator
from pyspark.ml.clustering import KMeans

credentials_path = "third-pad-387714-c6e74142c550.json"
client = bigquery.Client.from_service_account_json(credentials_path)


query = """
SELECT date, CAST(EXTRACT(HOUR FROM hour) AS INT64) AS hour, signal, network, operator, status, description, net, speed, satellites, precission, provider, activity, town_name
FROM bigquery-public-data.catalonian_mobile_coverage_eu.mobile_data_2015_2017 LIMIT 2000000;
"""
query_job = client.query(query)
results = query_job.result().to_dataframe()

results.dropna(inplace=True)
for col in ["signal", "speed", "satellites", "precission"]:
    results[col] = results[col].astype(float)

spark = SparkSession.builder.appName("BigQuery to PySpark").getOrCreate()

schema = StructType([
    StructField("date", DateType(), True),
    StructField("hour", IntegerType(), True),
    StructField("signal", FloatType(), True),
    StructField("network", StringType(), True),
    StructField("operator", StringType(), True),
    StructField("status", StringType(), True),
    StructField("description", StringType(), True),
    StructField("net", StringType(), True),
    StructField("speed", FloatType(), True),
    StructField("satellites", FloatType(), True),
    StructField("precission", FloatType(), True),
    StructField("provider", StringType(), True),
    StructField("activity", StringType(), True),
    StructField("town_name", StringType(), True),
])

pyspark_df = spark.createDataFrame(results, schema=schema)
pyspark_df = pyspark_df.dropna()

pyspark_df.printSchema()


row_count = pyspark_df.count()
print(f"Total rows: {row_count}")

filtered_df = pyspark_df.filter(pyspark_df.signal > 50)
filtered_df.show(10)

pyspark_df.selectExpr(
    "avg(speed) as avg_speed",
    "stddev(speed) as stddev_speed"
).show()

network_count = pyspark_df.groupBy("network").count()
network_count.show()

pyspark_df = pyspark_df.withColumn("speed_kbps", pyspark_df.speed * 1000)
pyspark_df.select("speed", "speed_kbps").show(5)

sorted_df = pyspark_df.orderBy(pyspark_df.speed.desc())
sorted_df.show(15)

pyspark_df.write.csv("output.csv", header=True)

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt

numeric_columns = ["signal", "speed", "satellites", "precission"]

correlations = {
    (col1, col2): pyspark_df.stat.corr(col1, col2)
    for col1 in numeric_columns for col2 in numeric_columns if col1 != col2
}

correlation_matrix = pd.DataFrame(index=numeric_columns, columns=numeric_columns)

for col1 in numeric_columns:
    for col2 in numeric_columns:
        if col1 == col2:
            correlation_matrix.loc[col1, col2] = 1.0
        else:
            correlation_matrix.loc[col1, col2] = pyspark_df.stat.corr(col1, col2)

correlation_matrix = correlation_matrix.astype(float)

print("Corelații între variabile:")
print(correlation_matrix)

plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", square=True)
plt.title("Matricea Corelațiilor între Variabile")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import pandas as pd


signal_counts = results['signal'].value_counts().sort_index()

fig_bar = px.bar(x=signal_counts.index,
                 y=signal_counts.values,
                 title='Distribuție Semnal',
                 labels={'x': 'Signal', 'y': 'Count'})
fig_bar.update_xaxes(type='category', tickangle=45)
fig_bar.show()


speed_hourly = results.groupby('hour')['speed'].mean().reset_index()

fig_line = px.line(speed_hourly,
                   x='hour',
                   y='speed',
                   title='Viteza Medie în Funcție de Oră',
                   labels={'hour': 'Hour of Day', 'speed': 'Average Speed (Mbps)'} )
fig_line.update_traces(mode='lines+markers')
fig_line.show()

!pip install mplcursors

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import mplcursors

data = results

plt.figure(figsize=(8, 6))
sns.scatterplot(x='signal', y='speed', data=data, alpha=0.5)
plt.xlabel("Semnal")
plt.ylabel("Viteză (Mbps)")
plt.title("Corelația dintre Semnal și Viteză")
plt.tight_layout()
plt.show()


data_subset = data.groupby('date')['speed'].mean().reset_index()

fig = px.line(data_subset, x='date', y='speed',
              title="Evoluția Vitezei în Funcție de Dată",
              labels={"date": "Data", "speed": "Viteză Medie (Mbps)"},
              template="plotly_dark")
fig.update_xaxes(rangeslider_visible=True)
fig.show()


network_count = data['network'].value_counts(normalize=True).reset_index()
network_count.columns = ['Network', 'Proportion']


threshold = 0.2
network_count['Network'] = network_count.apply(
    lambda row: row['Network'] if row['Proportion'] > threshold else 'Alte rețele',
    axis=1
)

grouped_network_count = network_count.groupby('Network', as_index=False).sum()
grouped_network_count = grouped_network_count.sort_values(by='Proportion', ascending=False)
grouped_network_count['Proportion'] *= 100


fig = px.pie(
    grouped_network_count,
    names='Network',
    values='Proportion',
    title="Distribuția Rețelelor",
    hole=0.2
)


fig.update_traces(
    textinfo='percent+label',
    pull=[0.05 if name != 'Alte rețele' else 0 for name in grouped_network_count['Network']]
)
fig.update_layout(
    showlegend=True,
    legend_title="Rețele",

)

fig.show()

bubble_data = data.sample(500)  # eșantion
plt.figure(figsize=(10, 6))
scatter = plt.scatter(
    bubble_data['signal'],
    bubble_data['speed'],
    s=bubble_data['satellites'] * 20,  # Dimensiune proporțională cu sateliții
    alpha=0.5,
    c=bubble_data['precission'],  # Culoare bazată pe precizie
    cmap='viridis'
)
plt.colorbar(scatter, label="Precizie")
plt.xlabel("Semnal")
plt.ylabel("Viteză (Mbps)")
plt.title("Relația Dintre Semnal, Viteză și Sateliți")
plt.tight_layout()
plt.show()


fig_3d = px.scatter_3d(data.sample(1000), x='signal', y='speed', z='precission',
                        color='precission',
                        title='Relația Dintre Semnal, Viteză și Precizie',
                        labels={'signal': 'Semnal', 'speed': 'Viteză (Mbps)', 'precission': 'Precizie'},
                        opacity=0.7)
fig_3d.update_traces(marker=dict(size=5))
fig_3d.show()


fig_hist = px.histogram(data, x='precission', nbins=50,
                        title='Distribuția Preciziei',
                        labels={'precission': 'Precizie'},
                        opacity=0.7, color_discrete_sequence=['royalblue'])
fig_hist.update_layout(bargap=0.1)
fig_hist.show()


fig_hist = px.histogram(
    results,
    x='speed',
    nbins=50,
    title='Distribuția Vitezei (Histogramă Interactivă)',
    labels={'speed': 'Viteză (Mbps)', 'count': 'Frecvență'},
    opacity=0.75,
    color_discrete_sequence=['indianred']
)
fig_hist.update_layout(bargap=0.1)
fig_hist.show()

import plotly.express as px

sunburst_data = results.groupby(['operator', 'network', 'activity']).size().reset_index(name='count')

fig_sunburst = px.sunburst(
    sunburst_data,
    path=['operator', 'network', 'activity'],
    values='count',
    title="Distribuția Ierarhică a Operatorilor, Rețelelor și Activităților",
    color='count',
    color_continuous_scale='RdBu'
)

fig_sunburst.show()


assembler = VectorAssembler(inputCols=["signal", "speed", "satellites", "precission"], outputCol="features")
ml_df = assembler.transform(pyspark_df)

train, test = ml_df.randomSplit([0.8, 0.2], seed=42)

logreg = LogisticRegression(featuresCol="features", labelCol="signal")
logreg_model = logreg.fit(train)
logreg_predictions = logreg_model.transform(test)
evaluator = MulticlassClassificationEvaluator(labelCol="signal", predictionCol="prediction", metricName="accuracy")
print("Logistic Regression Accuracy:", evaluator.evaluate(logreg_predictions))

import pandas as pd
import plotly.graph_objects as go

test_results = logreg_predictions.select("signal", "prediction").toPandas()
test_results_sorted = test_results.sort_values(by="signal").reset_index(drop=True)

fig = go.Figure()

fig.add_trace(go.Scatter(
    x=test_results_sorted.index,
    y=test_results_sorted['signal'],
    mode='lines',
    name='Actual',
    line=dict(width=2)
))


fig.add_trace(go.Scatter(
    x=test_results_sorted.index,
    y=test_results_sorted['prediction'],
    mode='lines',
    name='Predicted',
    line=dict(width=2, dash='dash')
))


fig.update_layout(
    title='Compararea Valorilor Actuale vs Predicții',
    xaxis_title='Index Date Test',
    yaxis_title='Semnal (Signal)',
    template='plotly',
    hovermode='x unified',
    showlegend=True
)


fig.update_xaxes(showgrid=True, rangeslider_visible=True)
fig.update_yaxes(showgrid=True)

fig.show()


dt = DecisionTreeClassifier(featuresCol="features", labelCol="signal")
dt_model = dt.fit(train)
dt_predictions = dt_model.transform(test)
print("Decision Tree Accuracy:", evaluator.evaluate(dt_predictions))

rf = RandomForestClassifier(featuresCol="features", labelCol="signal")
rf_model = rf.fit(train)
rf_predictions = rf_model.transform(test)
print("Random Forest Accuracy:", evaluator.evaluate(rf_predictions))

import pandas as pd
import plotly.graph_objects as go

dt_results = dt_predictions.select("signal", "prediction").toPandas().sort_values(by="signal").reset_index(drop=True)
rf_results = rf_predictions.select("signal", "prediction").toPandas().sort_values(by="signal").reset_index(drop=True)

fig_dt = go.Figure()

fig_dt.add_trace(go.Scatter(
    x=dt_results.index, y=dt_results['signal'],
    mode='lines', name='Actual Signal', line=dict(width=2)
))
fig_dt.add_trace(go.Scatter(
    x=dt_results.index, y=dt_results['prediction'],
    mode='lines', name='Predicted Signal', line=dict(width=2, dash='dash')
))

fig_dt.update_layout(
    title='Compararea Valorilor Actuale vs Predicții (Decision Tree)',
    xaxis_title='Index Date Test',
    yaxis_title='Semnal (Signal)',
    template='plotly_dark',
    hovermode='x unified'
)

fig_dt.show()

fig_rf = go.Figure()

fig_rf.add_trace(go.Scatter(
    x=rf_results.index, y=rf_results['signal'],
    mode='lines', name='Actual Signal', line=dict(width=2)
))
fig_rf.add_trace(go.Scatter(
    x=rf_results.index, y=rf_results['prediction'],
    mode='lines', name='Predicted Signal', line=dict(width=2, dash='dash')
))

fig_rf.update_layout(
    title='Compararea Valorilor Actuale vs Predicții (Random Forest)',
    xaxis_title='Index Date Test',
    yaxis_title='Semnal (Signal)',
    template='plotly_dark',
    hovermode='x unified'
)

fig_rf.show()

from pyspark.ml.clustering import KMeans
from pyspark.ml.evaluation import ClusteringEvaluator


kmeans = KMeans(featuresCol="features", k=3, seed=42)
kmeans_model = kmeans.fit(ml_df)
kmeans_predictions = kmeans_model.transform(ml_df)


evaluator = ClusteringEvaluator()
silhouette = evaluator.evaluate(kmeans_predictions)
print(f"Silhouette Score: {silhouette}")


kmeans_results = kmeans_predictions.select("signal", "speed", "satellites", "precission", "prediction").toPandas()

import plotly.express as px

fig_kmeans = px.scatter_3d(
    kmeans_results,
    x='signal', y='speed', z='satellites',
    color=kmeans_results['prediction'].astype(str),
    title='K-Means Clustering: Semnal vs Viteză vs Sateliți',
    labels={"signal": "Semnal", "speed": "Viteză", "satellites": "Sateliți", "prediction": "Cluster"},
    opacity=0.7
)

fig_kmeans.show()
